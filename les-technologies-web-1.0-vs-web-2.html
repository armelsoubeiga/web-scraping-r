<!DOCTYPE html>
<html lang="french" xml:lang="french">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapitre 2 Les technologies web 1.0 vs web 2.0 | R pour l’extraction de données sur le web : textes, images, tables et pdfs</title>
  <meta name="description" content="Utilisation de R pour l’extraction des données sur le web." />
  <meta name="generator" content="bookdown 0.25.5 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapitre 2 Les technologies web 1.0 vs web 2.0 | R pour l’extraction de données sur le web : textes, images, tables et pdfs" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://r-webscraping.com//cover/coverface.jpg" />
  <meta property="og:description" content="Utilisation de R pour l’extraction des données sur le web." />
  <meta name="github-repo" content="armelsoubeiga/web-scraping-r" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapitre 2 Les technologies web 1.0 vs web 2.0 | R pour l’extraction de données sur le web : textes, images, tables et pdfs" />
  
  <meta name="twitter:description" content="Utilisation de R pour l’extraction des données sur le web." />
  <meta name="twitter:image" content="https://r-webscraping.com//cover/coverface.jpg" />

<meta name="author" content="Armel SOUBEIGA" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="généralités-sur-le-web-scraping.html"/>
<link rel="next" href="introduction-au-web-scraping.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">R pour l'extraction de données sur le web</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Avant-propos</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#à-quoi-attendre-de-ce-livre"><i class="fa fa-check"></i>À quoi attendre de ce livre</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#structure-du-livre"><i class="fa fa-check"></i>Structure du livre</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#ressources-et-scripts"><i class="fa fa-check"></i>Ressources et scripts</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#remerciements"><i class="fa fa-check"></i>Remerciements</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#dévouement"><i class="fa fa-check"></i>Dévouement</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#a-propos-de-lauteur"><i class="fa fa-check"></i>A propos de l’auteur</a></li>
</ul></li>
<li class="part"><span><b>I Généralités<span></span></b></span></li>
<li class="chapter" data-level="1" data-path="généralités-sur-le-web-scraping.html"><a href="généralités-sur-le-web-scraping.html"><i class="fa fa-check"></i><b>1</b> Généralités sur le web scraping</a>
<ul>
<li class="chapter" data-level="1.1" data-path="généralités-sur-le-web-scraping.html"><a href="généralités-sur-le-web-scraping.html#définitions"><i class="fa fa-check"></i><b>1.1</b> Définitions</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="généralités-sur-le-web-scraping.html"><a href="généralités-sur-le-web-scraping.html#data-scraping"><i class="fa fa-check"></i><b>1.1.1</b> Data Scraping</a></li>
<li class="chapter" data-level="1.1.2" data-path="généralités-sur-le-web-scraping.html"><a href="généralités-sur-le-web-scraping.html#le-web-scraping"><i class="fa fa-check"></i><b>1.1.2</b> Le web scraping</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="généralités-sur-le-web-scraping.html"><a href="généralités-sur-le-web-scraping.html#justification"><i class="fa fa-check"></i><b>1.2</b> Justification</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="généralités-sur-le-web-scraping.html"><a href="généralités-sur-le-web-scraping.html#collecter-des-données-rapidement-et-automatiquement"><i class="fa fa-check"></i><b>1.2.1</b> Collecter des données rapidement et automatiquement</a></li>
<li class="chapter" data-level="1.2.2" data-path="généralités-sur-le-web-scraping.html"><a href="généralités-sur-le-web-scraping.html#a-quoi-sert-le-web-scraping-au-sein-dune-entreprise"><i class="fa fa-check"></i><b>1.2.2</b> A quoi sert le web scraping au sein d’une entreprise ?</a></li>
<li class="chapter" data-level="1.2.3" data-path="généralités-sur-le-web-scraping.html"><a href="généralités-sur-le-web-scraping.html#la-surveillance-des-prix"><i class="fa fa-check"></i><b>1.2.3</b> La surveillance des prix</a></li>
<li class="chapter" data-level="1.2.4" data-path="généralités-sur-le-web-scraping.html"><a href="généralités-sur-le-web-scraping.html#étude-de-marché"><i class="fa fa-check"></i><b>1.2.4</b> Étude de marché</a></li>
<li class="chapter" data-level="1.2.5" data-path="généralités-sur-le-web-scraping.html"><a href="généralités-sur-le-web-scraping.html#apprentissage-automatique"><i class="fa fa-check"></i><b>1.2.5</b> Apprentissage automatique</a></li>
<li class="chapter" data-level="1.2.6" data-path="généralités-sur-le-web-scraping.html"><a href="généralités-sur-le-web-scraping.html#surveillance-des-actualités"><i class="fa fa-check"></i><b>1.2.6</b> Surveillance des actualités</a></li>
<li class="chapter" data-level="1.2.7" data-path="généralités-sur-le-web-scraping.html"><a href="généralités-sur-le-web-scraping.html#analyse-des-sentiments-et-relation-client"><i class="fa fa-check"></i><b>1.2.7</b> Analyse des sentiments et relation client</a></li>
<li class="chapter" data-level="1.2.8" data-path="généralités-sur-le-web-scraping.html"><a href="généralités-sur-le-web-scraping.html#marketing-par-courriel-et-la-prospection"><i class="fa fa-check"></i><b>1.2.8</b> Marketing par courriel et la prospection</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="généralités-sur-le-web-scraping.html"><a href="généralités-sur-le-web-scraping.html#légalité"><i class="fa fa-check"></i><b>1.3</b> Légalité</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="généralités-sur-le-web-scraping.html"><a href="généralités-sur-le-web-scraping.html#avertissement"><i class="fa fa-check"></i><b>1.3.1</b> AVERTISSEMENT</a></li>
<li class="chapter" data-level="1.3.2" data-path="généralités-sur-le-web-scraping.html"><a href="généralités-sur-le-web-scraping.html#aperçu"><i class="fa fa-check"></i><b>1.3.2</b> Aperçu</a></li>
<li class="chapter" data-level="1.3.3" data-path="généralités-sur-le-web-scraping.html"><a href="généralités-sur-le-web-scraping.html#comment-éviter-les-ennuis"><i class="fa fa-check"></i><b>1.3.3</b> Comment éviter les ennuis ?</a></li>
<li class="chapter" data-level="1.3.4" data-path="généralités-sur-le-web-scraping.html"><a href="généralités-sur-le-web-scraping.html#analyse-dun-fichier-robots.txt"><i class="fa fa-check"></i><b>1.3.4</b> Analyse d’un fichier robots.txt</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="généralités-sur-le-web-scraping.html"><a href="généralités-sur-le-web-scraping.html#outils-et-méthodes"><i class="fa fa-check"></i><b>1.4</b> Outils et méthodes</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="généralités-sur-le-web-scraping.html"><a href="généralités-sur-le-web-scraping.html#les-bases-du-web-scraping"><i class="fa fa-check"></i><b>1.4.1</b> Les Bases du web scraping</a></li>
<li class="chapter" data-level="1.4.2" data-path="généralités-sur-le-web-scraping.html"><a href="généralités-sur-le-web-scraping.html#comment-démarrer-un-projet-de-web-scraping"><i class="fa fa-check"></i><b>1.4.2</b> Comment démarrer un projet de web scraping</a></li>
<li class="chapter" data-level="1.4.3" data-path="généralités-sur-le-web-scraping.html"><a href="généralités-sur-le-web-scraping.html#quelles-compétences-pour-développer-son-web-scraper"><i class="fa fa-check"></i><b>1.4.3</b> Quelles compétences pour développer son web scraper ?</a></li>
<li class="chapter" data-level="1.4.4" data-path="généralités-sur-le-web-scraping.html"><a href="généralités-sur-le-web-scraping.html#quelle-alternative-si-vous-navez-pas-de-compétences-techniques"><i class="fa fa-check"></i><b>1.4.4</b> Quelle alternative si vous n’avez pas de compétences techniques ?</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="généralités-sur-le-web-scraping.html"><a href="généralités-sur-le-web-scraping.html#prérequis"><i class="fa fa-check"></i><b>1.5</b> Prérequis</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="les-technologies-web-1.0-vs-web-2.html"><a href="les-technologies-web-1.0-vs-web-2.html"><i class="fa fa-check"></i><b>2</b> Les technologies web 1.0 vs web 2.0</a>
<ul>
<li class="chapter" data-level="2.1" data-path="les-technologies-web-1.0-vs-web-2.html"><a href="les-technologies-web-1.0-vs-web-2.html#le-web-1.0-le-web-statique"><i class="fa fa-check"></i><b>2.1</b> Le web 1.0 : le web statique</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="les-technologies-web-1.0-vs-web-2.html"><a href="les-technologies-web-1.0-vs-web-2.html#la-communication-web-client-serveur"><i class="fa fa-check"></i><b>2.1.1</b> La communication web client-serveur</a></li>
<li class="chapter" data-level="2.1.2" data-path="les-technologies-web-1.0-vs-web-2.html"><a href="les-technologies-web-1.0-vs-web-2.html#http-règles-de-communication-web"><i class="fa fa-check"></i><b>2.1.2</b> HTTP : règles de communication web</a></li>
<li class="chapter" data-level="2.1.3" data-path="les-technologies-web-1.0-vs-web-2.html"><a href="les-technologies-web-1.0-vs-web-2.html#exploration-http-avec-r"><i class="fa fa-check"></i><b>2.1.3</b> Exploration HTTP avec R</a></li>
<li class="chapter" data-level="2.1.4" data-path="les-technologies-web-1.0-vs-web-2.html"><a href="les-technologies-web-1.0-vs-web-2.html#les-urls"><i class="fa fa-check"></i><b>2.1.4</b> Les URLs</a></li>
<li class="chapter" data-level="2.1.5" data-path="les-technologies-web-1.0-vs-web-2.html"><a href="les-technologies-web-1.0-vs-web-2.html#conception-de-base-du-web-dynamique"><i class="fa fa-check"></i><b>2.1.5</b> Conception de base du web dynamique</a></li>
<li class="chapter" data-level="2.1.6" data-path="les-technologies-web-1.0-vs-web-2.html"><a href="les-technologies-web-1.0-vs-web-2.html#les-aspects-clés-de-lextraction-automatisée-de-données-web"><i class="fa fa-check"></i><b>2.1.6</b> Les aspects clés de l’extraction automatisée de données web</a></li>
<li class="chapter" data-level="2.1.7" data-path="les-technologies-web-1.0-vs-web-2.html"><a href="les-technologies-web-1.0-vs-web-2.html#api-et-site-web-dynamique"><i class="fa fa-check"></i><b>2.1.7</b> API et site web dynamique</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="les-technologies-web-1.0-vs-web-2.html"><a href="les-technologies-web-1.0-vs-web-2.html#en-conclusion"><i class="fa fa-check"></i><b>2.2</b> En conclusion</a></li>
</ul></li>
<li class="part"><span><b>II La collecte des données sans APIs<span></span></b></span></li>
<li class="chapter" data-level="3" data-path="introduction-au-web-scraping.html"><a href="introduction-au-web-scraping.html"><i class="fa fa-check"></i><b>3</b> Introduction au web scraping</a>
<ul>
<li class="chapter" data-level="3.1" data-path="introduction-au-web-scraping.html"><a href="introduction-au-web-scraping.html#les-logiciels-de-web-scraping-gratuits"><i class="fa fa-check"></i><b>3.1</b> Les logiciels de web scraping gratuits</a></li>
<li class="chapter" data-level="3.2" data-path="introduction-au-web-scraping.html"><a href="introduction-au-web-scraping.html#comment-faire-du-web-scraping-avec-r"><i class="fa fa-check"></i><b>3.2</b> Comment faire du web-scraping avec R ?</a></li>
<li class="chapter" data-level="3.3" data-path="introduction-au-web-scraping.html"><a href="introduction-au-web-scraping.html#identifier-les-éléments-dintérêt-dans-une-page"><i class="fa fa-check"></i><b>3.3</b> Identifier les éléments d’intérêt dans une page</a></li>
<li class="chapter" data-level="3.4" data-path="introduction-au-web-scraping.html"><a href="introduction-au-web-scraping.html#les-packages-r-dédiées-au-web-scraping"><i class="fa fa-check"></i><b>3.4</b> Les packages R dédiées au web scraping</a></li>
<li class="chapter" data-level="3.5" data-path="introduction-au-web-scraping.html"><a href="introduction-au-web-scraping.html#lextraction-des-données-avec-le-package-rvest"><i class="fa fa-check"></i><b>3.5</b> L’extraction des données avec le package rvest</a></li>
<li class="chapter" data-level="3.6" data-path="introduction-au-web-scraping.html"><a href="introduction-au-web-scraping.html#lextraction-des-données-avec-le-package-rcrawler"><i class="fa fa-check"></i><b>3.6</b> L’extraction des données avec le package Rcrawler</a></li>
<li class="chapter" data-level="3.7" data-path="introduction-au-web-scraping.html"><a href="introduction-au-web-scraping.html#lextraction-des-données-avec-le-package-rselenium"><i class="fa fa-check"></i><b>3.7</b> L’extraction des données avec le package RSelenium</a></li>
<li class="chapter" data-level="3.8" data-path="introduction-au-web-scraping.html"><a href="introduction-au-web-scraping.html#la-différence-entre-rvest-et-rselenium"><i class="fa fa-check"></i><b>3.8</b> La différence entre rvest et RSelenium</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="le-scraping-2.0-pour-le-web-dynamique.html"><a href="le-scraping-2.0-pour-le-web-dynamique.html"><i class="fa fa-check"></i><b>4</b> Le Scraping 2.0 pour le web dynamique</a>
<ul>
<li class="chapter" data-level="4.1" data-path="le-scraping-2.0-pour-le-web-dynamique.html"><a href="le-scraping-2.0-pour-le-web-dynamique.html#comment-scraper-un-site-web-dynamique"><i class="fa fa-check"></i><b>4.1</b> Comment scraper un site web dynamique ?</a></li>
<li class="chapter" data-level="4.2" data-path="le-scraping-2.0-pour-le-web-dynamique.html"><a href="le-scraping-2.0-pour-le-web-dynamique.html#cookies"><i class="fa fa-check"></i><b>4.2</b> Cookies</a></li>
<li class="chapter" data-level="4.3" data-path="le-scraping-2.0-pour-le-web-dynamique.html"><a href="le-scraping-2.0-pour-le-web-dynamique.html#ajax-et-xhr"><i class="fa fa-check"></i><b>4.3</b> AJAX et XHR</a></li>
<li class="chapter" data-level="4.4" data-path="le-scraping-2.0-pour-le-web-dynamique.html"><a href="le-scraping-2.0-pour-le-web-dynamique.html#selenium"><i class="fa fa-check"></i><b>4.4</b> Selenium</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="cas-pratiques-des-projets-dextraction-de-données-textuelles.html"><a href="cas-pratiques-des-projets-dextraction-de-données-textuelles.html"><i class="fa fa-check"></i><b>5</b> Cas pratiques : des projets d’extraction de données textuelles</a>
<ul>
<li class="chapter" data-level="5.1" data-path="cas-pratiques-des-projets-dextraction-de-données-textuelles.html"><a href="cas-pratiques-des-projets-dextraction-de-données-textuelles.html#projet-1-données-dun-site-de-e-commerce"><i class="fa fa-check"></i><b>5.1</b> Projet 1 : données d’un site de e-commerce</a></li>
<li class="chapter" data-level="5.2" data-path="cas-pratiques-des-projets-dextraction-de-données-textuelles.html"><a href="cas-pratiques-des-projets-dextraction-de-données-textuelles.html#projet-2-collecte-de-coorpus-paire-pour-un-modèle-de-traduction"><i class="fa fa-check"></i><b>5.2</b> Projet 2 : Collecte de coorpus paire pour un modèle de traduction</a></li>
<li class="chapter" data-level="5.3" data-path="cas-pratiques-des-projets-dextraction-de-données-textuelles.html"><a href="cas-pratiques-des-projets-dextraction-de-données-textuelles.html#projet-3-collecte-de-données-pour-un-système-de-recommandation"><i class="fa fa-check"></i><b>5.3</b> Projet 3 : Collecte de données pour un système de recommandation</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="cas-pratiques-des-projets-dextraction-de-tableaux-de-données.html"><a href="cas-pratiques-des-projets-dextraction-de-tableaux-de-données.html"><i class="fa fa-check"></i><b>6</b> Cas pratiques : des projets d’extraction de tableaux de données</a>
<ul>
<li class="chapter" data-level="6.1" data-path="cas-pratiques-des-projets-dextraction-de-tableaux-de-données.html"><a href="cas-pratiques-des-projets-dextraction-de-tableaux-de-données.html#projet-1-extration-des-tables-statistiques-du-football"><i class="fa fa-check"></i><b>6.1</b> Projet 1 : Extration des tables statistiques du Football</a></li>
<li class="chapter" data-level="6.2" data-path="cas-pratiques-des-projets-dextraction-de-tableaux-de-données.html"><a href="cas-pratiques-des-projets-dextraction-de-tableaux-de-données.html#projet-2-les-tableaux-statistiques-sur-lemploi-du-bls"><i class="fa fa-check"></i><b>6.2</b> Projet 2 : Les tableaux statistiques sur l’emploi du BLS</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="cas-pratiques-des-projets-dextraction-des-images-et-pdfs.html"><a href="cas-pratiques-des-projets-dextraction-des-images-et-pdfs.html"><i class="fa fa-check"></i><b>7</b> Cas pratiques : des projets d’extraction des images et pdfs</a>
<ul>
<li class="chapter" data-level="7.1" data-path="cas-pratiques-des-projets-dextraction-des-images-et-pdfs.html"><a href="cas-pratiques-des-projets-dextraction-des-images-et-pdfs.html#projet-1-waxclassification---collecte-dimages-pour-une-app-dia"><i class="fa fa-check"></i><b>7.1</b> Projet 1 : WaxClassification - Collecte d’images pour une app d’IA</a></li>
<li class="chapter" data-level="7.2" data-path="cas-pratiques-des-projets-dextraction-des-images-et-pdfs.html"><a href="cas-pratiques-des-projets-dextraction-des-images-et-pdfs.html#projet-2-reporthub---collecte-de-rapports-annuels-dentreprises"><i class="fa fa-check"></i><b>7.2</b> Projet 2 : ReportHub - Collecte de rapports annuels d’entreprises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="automatisation-de-scrapers-sur-le-cloud-ou-serveur-local.html"><a href="automatisation-de-scrapers-sur-le-cloud-ou-serveur-local.html"><i class="fa fa-check"></i><b>8</b> Automatisation de scrapers sur le cloud ou serveur local</a>
<ul>
<li class="chapter" data-level="8.1" data-path="automatisation-de-scrapers-sur-le-cloud-ou-serveur-local.html"><a href="automatisation-de-scrapers-sur-le-cloud-ou-serveur-local.html#google-cloud-et-lautomatisation-du-scraping"><i class="fa fa-check"></i><b>8.1</b> Google Cloud et l’automatisation du scraping</a></li>
<li class="chapter" data-level="8.2" data-path="automatisation-de-scrapers-sur-le-cloud-ou-serveur-local.html"><a href="automatisation-de-scrapers-sur-le-cloud-ou-serveur-local.html#mon-ordinateur-et-lautomatisation-du-scraping"><i class="fa fa-check"></i><b>8.2</b> Mon ordinateur et l’automatisation du scraping</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="le-package-de-scraping-afnews.html"><a href="le-package-de-scraping-afnews.html"><i class="fa fa-check"></i><b>9</b> Le package de scraping afnews</a>
<ul>
<li class="chapter" data-level="9.1" data-path="le-package-de-scraping-afnews.html"><a href="le-package-de-scraping-afnews.html#présentation-de-afnews"><i class="fa fa-check"></i><b>9.1</b> Présentation de afnews</a></li>
<li class="chapter" data-level="9.2" data-path="le-package-de-scraping-afnews.html"><a href="le-package-de-scraping-afnews.html#installation"><i class="fa fa-check"></i><b>9.2</b> Installation</a></li>
</ul></li>
<li class="part"><span><b>III APIs scraping<span></span></b></span></li>
<li class="chapter" data-level="10" data-path="le-web-scraping-avancé-avec-api.html"><a href="le-web-scraping-avancé-avec-api.html"><i class="fa fa-check"></i><b>10</b> Le web scraping avancé avec API</a>
<ul>
<li class="chapter" data-level="10.1" data-path="le-web-scraping-avancé-avec-api.html"><a href="le-web-scraping-avancé-avec-api.html#le-rôle-des-apis-web-pour-lextraction-des-données"><i class="fa fa-check"></i><b>10.1</b> Le rôle des APIs web pour l’extraction des données</a></li>
<li class="chapter" data-level="10.2" data-path="le-web-scraping-avancé-avec-api.html"><a href="le-web-scraping-avancé-avec-api.html#une-api-au-lieu-dun-web-scraper"><i class="fa fa-check"></i><b>10.2</b> Une API au lieu d’un web scraper</a></li>
<li class="chapter" data-level="10.3" data-path="le-web-scraping-avancé-avec-api.html"><a href="le-web-scraping-avancé-avec-api.html#les-apis-web-publiquement-accessible"><i class="fa fa-check"></i><b>10.3</b> Les APIs web publiquement accessible</a></li>
<li class="chapter" data-level="10.4" data-path="le-web-scraping-avancé-avec-api.html"><a href="le-web-scraping-avancé-avec-api.html#api-cassée"><i class="fa fa-check"></i><b>10.4</b> API cassée</a></li>
<li class="chapter" data-level="10.5" data-path="le-web-scraping-avancé-avec-api.html"><a href="le-web-scraping-avancé-avec-api.html#les-apis-web-fermés"><i class="fa fa-check"></i><b>10.5</b> Les APIs web fermés</a></li>
</ul></li>
<li class="part"><span><b>IV Les robots Crawlers du web<span></span></b></span></li>
<li class="chapter" data-level="11" data-path="le-minage-et-lexploration-du-web.html"><a href="le-minage-et-lexploration-du-web.html"><i class="fa fa-check"></i><b>11</b> Le minage et l’exploration du web</a>
<ul>
<li class="chapter" data-level="11.1" data-path="le-minage-et-lexploration-du-web.html"><a href="le-minage-et-lexploration-du-web.html#les-avantages-dun-robot-dexploration-web"><i class="fa fa-check"></i><b>11.1</b> Les avantages d’un robot d’exploration web</a></li>
<li class="chapter" data-level="11.2" data-path="le-minage-et-lexploration-du-web.html"><a href="le-minage-et-lexploration-du-web.html#lalgorithme-de-base-dun-crawler"><i class="fa fa-check"></i><b>11.2</b> L’algorithme de base d’un crawler</a></li>
<li class="chapter" data-level="11.3" data-path="le-minage-et-lexploration-du-web.html"><a href="le-minage-et-lexploration-du-web.html#mise-en-œuvre-pratique"><i class="fa fa-check"></i><b>11.3</b> Mise en œuvre pratique</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="limplémentation-dun-robot-crawler.html"><a href="limplémentation-dun-robot-crawler.html"><i class="fa fa-check"></i><b>12</b> L’implémentation d’un robot Crawler</a>
<ul>
<li class="chapter" data-level="12.1" data-path="limplémentation-dun-robot-crawler.html"><a href="limplémentation-dun-robot-crawler.html#les-problèmes-de-mise-en-œuvre-dun-robot-crawler"><i class="fa fa-check"></i><b>12.1</b> Les problèmes de mise en œuvre d’un robot crawler</a></li>
<li class="chapter" data-level="12.2" data-path="limplémentation-dun-robot-crawler.html"><a href="limplémentation-dun-robot-crawler.html#limplémentation-dun-crawler-avec-rcrawler"><i class="fa fa-check"></i><b>12.2</b> L’implémentation d’un crawler avec Rcrawler</a></li>
</ul></li>
<li class="part"><span><b>V Bibliographie<span></span></b></span></li>
<li class="chapter" data-level="" data-path="référence-bibliographique.html"><a href="référence-bibliographique.html"><i class="fa fa-check"></i>Référence bibliographique</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R pour l’extraction de données sur le web : textes, images, tables et pdfs</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="les-technologies-web-1.0-vs-web-2.0" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Chapitre 2</span> Les technologies web 1.0 vs web 2.0<a href="les-technologies-web-1.0-vs-web-2.html#les-technologies-web-1.0-vs-web-2.0" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Les tâches d’exploration des données web (web maning en anglais) font généralement face à deux types de sites web. Il s’agit des sites web statiques basés sur le web 1.0 et les sites web dynamiques basés sur la technologie web 2.0 .</p>
<div id="le-web-1.0-le-web-statique" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Le web 1.0 : le web statique<a href="les-technologies-web-1.0-vs-web-2.html#le-web-1.0-le-web-statique" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="la-communication-web-client-serveur" class="section level3 hasAnchor" number="2.1.1">
<h3><span class="header-section-number">2.1.1</span> La communication web client-serveur<a href="les-technologies-web-1.0-vs-web-2.html#la-communication-web-client-serveur" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>L’ensemble des technologies web sont étroitement liées au modèle <strong>client-serveur</strong>(HTTP). Dans un modèle client-serveur, les tâches du système sont réparties entre les fournisseurs d’une ressource (documents, données, images, …), appelés <strong>serveurs</strong>, et les demandeurs de cette ressource, appelés <strong>clients</strong>. Dans le <a href="https://fr.wikipedia.org/wiki/World_Wide_Web">world wide web</a>, les clients les plus courants sont les navigateurs web et les serveurs les plus courants sont les serveurs web hébergeant des sites web.</p>
<p>Par exemple sur l’image ci-dessous, on peut voir les clients à gauche qui communiquent avec le serveur à droite sur l’internet et à travers du http.</p>
<p><img src="images/img17.png" /></p>
<p>Ainsi, un aspect clé du web scraping est de savoir comment contrôler (et automatiser) le côté client des intéractions client-serveur. Autrement dit, nous devons comprendre comment la communication client-serveur fonctionne essentiellement du point de vue du client. En terme clair, comment fonctionne le http.</p>
</div>
<div id="http-règles-de-communication-web" class="section level3 hasAnchor" number="2.1.2">
<h3><span class="header-section-number">2.1.2</span> HTTP : règles de communication web<a href="les-technologies-web-1.0-vs-web-2.html#http-règles-de-communication-web" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Le <a href="https://tinyurl.com/2zzujwwt">protocole HTTP</a> est une norme très courante qui guide l’échange de documents sur le web et qui est pertinente pour le web scraping. En principe, HTTP est un ensemble de conventions qui définissent comment la communication entre le client et le serveur démarre et s’arrête, à quoi ressemblent les requêtes d’un client et les réponses du serveur, ainsi que le fonctionnement de l’authentification des utilisateurs (clients) pour les documents à accès restreint.</p>
<p>La méthode HTTP la plus simple est la requête <strong>GET</strong> utilisée par un client pour demander simplement à un serveur d’envoyer une page web spécifique. Une requête GET typique pour obtenir la page des formations offertes par l’UNIVERSITE CLERMONT AUVERGNE pourrait ressembler à ceci :</p>
<pre><code>GET /formation/nos-formations/
      par-ufr-ecoles-et-instituts HTTP/1.1
      
Host: www.uca.fr</code></pre>
<p>La première ligne est la ligne de requête indiquant ce que le client veut faire, <code>GET</code> : – <code>/formation~~par-ufr-ecoles</code> représente le chemin et – <code>HTTP/1.1</code> la version du protocole. La deuxième ligne <code>Host: www.uca.fr</code> et les lignes suivantes constituent les <strong>en-têtes HTTP</strong>, indiquant au serveur le nom d’hôte du site web où se trouve le document demandé.</p>
<p>Si tout se passe bien avec la requête, la réponse HTTP du serveur commencerait alors par :</p>
<pre><code>HTTP/1.1 200 OK
Content-Type: text/html</code></pre>
<p>La première ligne est la <strong>ligne d’état</strong>, elle indique le protocole utilisé par le serveur, puis le code d’état de la réponse (ici 200) et un message de statut (ici OK). La deuxième ligne donne le type de contenu de la réponse. Les <strong>en-têtes de réponse</strong> sont utiles pour interpréter le corps de la réponse par le navigateur. Ainsi, connaitre les codes d’état de réponse HTTP et les types de contenus de réponse est donc très utile et peut aider le web scraper à automatiser l’extraction. <a href="https://tinyurl.com/27c955en">Voici une liste des codes d’état HTTP et leur signification</a>.</p>
<p>Une autre méthode HTTP couramment utilisée est la requête <code>POST</code> qui permet au navigateur d’envoyer des informations à un serveur. Les requêtes <code>POST</code> sont souvent utilisées lors de la soumission d’un formulaire HTML sur une page web. Par exemple, si nous voulons nous connecter à une page web avec un contenu protégé, comme la page Facebook personnelle, nous sommes invités à entrer un nom d’utilisateur et un mot de passe. Lorsque nous appuyons sur le bouton <strong>Connexion</strong>, nous envoyons une requête <code>POST</code> qui ressemble à ceci :</p>
<pre><code>POST /login.php HTTP/1.1
Host: www.facebook.com
..
email=username@example.com&amp;pass=12345</code></pre>
</div>
<div id="exploration-http-avec-r" class="section level3 hasAnchor" number="2.1.3">
<h3><span class="header-section-number">2.1.3</span> Exploration HTTP avec R<a href="les-technologies-web-1.0-vs-web-2.html#exploration-http-avec-r" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="les-urls" class="section level3 hasAnchor" number="2.1.4">
<h3><span class="header-section-number">2.1.4</span> Les URLs<a href="les-technologies-web-1.0-vs-web-2.html#les-urls" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="conception-de-base-du-web-dynamique" class="section level3 hasAnchor" number="2.1.5">
<h3><span class="header-section-number">2.1.5</span> Conception de base du web dynamique<a href="les-technologies-web-1.0-vs-web-2.html#conception-de-base-du-web-dynamique" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="les-aspects-clés-de-lextraction-automatisée-de-données-web" class="section level3 hasAnchor" number="2.1.6">
<h3><span class="header-section-number">2.1.6</span> Les aspects clés de l’extraction automatisée de données web<a href="les-technologies-web-1.0-vs-web-2.html#les-aspects-clés-de-lextraction-automatisée-de-données-web" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="api-et-site-web-dynamique" class="section level3 hasAnchor" number="2.1.7">
<h3><span class="header-section-number">2.1.7</span> API et site web dynamique<a href="les-technologies-web-1.0-vs-web-2.html#api-et-site-web-dynamique" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
</div>
<div id="en-conclusion" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> En conclusion<a href="les-technologies-web-1.0-vs-web-2.html#en-conclusion" class="anchor-section" aria-label="Anchor link to header"></a></h2>

</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="généralités-sur-le-web-scraping.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="introduction-au-web-scraping.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/armelsoubeiga/web-scraping-r/edit/master/02.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["r-web-scraping.pdf", "r-web-scraping.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

</body>

</html>
